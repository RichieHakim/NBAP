{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4772327",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conda Environment: roicat\n"
     ]
    }
   ],
   "source": [
    "# widen jupyter notebook window\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important; }</style>\"))\n",
    "\n",
    "# check environment\n",
    "import os\n",
    "print(f'Conda Environment: ' + os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8329947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3568ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorly as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c60fa0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import bnpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91582396",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.set_backend('pytorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de99bc",
   "metadata": {},
   "source": [
    "Import face_rhythm TCA factors and spectrogram tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f5447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_save = r'/home/rich/Desktop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d07823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_FR_template = r'/media/rich/bigSSD/analysis_data/face_rhythm/mouse_0322N/20230430/run_from_o2'\n",
    "directory_FR_current = r'/media/rich/bigSSD/analysis_data/face_rhythm/mouse_0322N/20230502//jobNum_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bbf38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tca_template = bnpm.h5_handling.simple_load(str(Path(directory_FR_template) / 'analysis_files' / 'TCA.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f46729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tca_current = bnpm.h5_handling.simple_load(str(Path(directory_FR_current) / 'analysis_files' / 'TCA.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20335165",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_template = bnpm.file_helpers.json_load(str(Path(directory_FR_template) / 'params.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74392ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: 'cpu'\n"
     ]
    }
   ],
   "source": [
    "DEVICE_data = bnpm.torch_helpers.set_device(use_GPU=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09f6fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_dict_to_cp_tensor(cp_dict, device='cpu'):\n",
    "    \"\"\"A function for converting a raw list of factor matrices into tensorly's CPTensor format\"\"\"\n",
    "    return tl.cp_tensor.CPTensor((None, [torch.as_tensor(v, dtype=torch.float32, device=device) for v in cp_dict.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "381a3c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cp_init(k_tensor, shape_dense_tensor, modes_fixed=[0,1,], device='cpu'):\n",
    "    \"\"\"Makes a CPTensor for initializing a TCA run. The k_tensor matrices will be used for each of the fixed modes and will be shuffle permuted for each of the non-fixed modes.\"\"\"\n",
    "    import copy\n",
    "    n_modes = len(k_tensor)\n",
    "    kt = [None]*n_modes\n",
    "    for i_mode in range(len(kt)):\n",
    "        if i_mode in modes_fixed:\n",
    "            kt[i_mode] = torch.as_tensor(k_tensor[i_mode], dtype=torch.float32, device=device)\n",
    "        else:\n",
    "            perm = torch.randperm(shape_dense_tensor[i_mode])\n",
    "            kt[i_mode] = torch.as_tensor(k_tensor[i_mode], dtype=torch.float32, device=device)[perm]\n",
    "        \n",
    "    return tl.cp_tensor.CPTensor((None, kt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "145e94f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_EV(tensor, cp):\n",
    "#     tensor_rec = tl.cp_to_tensor(cp).cpu()\n",
    "    tensor_rec = bnpm.indexing.kruskal_to_dense(cp.factors).cpu()\n",
    "    ev = 1 - (torch.var(tensor - tensor_rec) / torch.var(tensor))\n",
    "    return ev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4747583",
   "metadata": {},
   "source": [
    "make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad2581a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_current = bnpm.h5_handling.simple_load(str(Path(directory_FR_current) / 'analysis_files' / 'VQT_Analyzer.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4615e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare the current session spectrogram for refitting\n",
    "### flatten the (xy points) dimension\n",
    "s = spec_current['spectrograms']['0'].copy()\n",
    "s = s.transpose(2,3,0,1)\n",
    "s = s.reshape(s.shape[0], s.shape[1], -1)\n",
    "s = s.transpose(2,0,1)\n",
    "s = torch.as_tensor(s, dtype=torch.float32, device=DEVICE_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dc56980",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare tca factors into a tensorly CPTensor\n",
    "cp_template = cp_dict_to_cp_tensor(tca_template['factors_rearranged']['0'], device=DEVICE_data)\n",
    "cp_current = cp_dict_to_cp_tensor(tca_current['factors_rearranged']['0'], device=DEVICE_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d63c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac7873a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: 'cpu'\n"
     ]
    }
   ],
   "source": [
    "DEVICE_tca = bnpm.torch_helpers.set_device(use_GPU=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19cee488",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes_fixed = [0,1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "997bb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_init = make_cp_init(cp_template.factors, s.shape, modes_fixed=modes_fixed, device=DEVICE_tca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80e41cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_tca = copy.deepcopy(params_template['TCA']['fit']['params_method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f046e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_tca['n_iter_max'] = 40\n",
    "params_tca['init'] = cp_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24df9d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tca = tl.decomposition.CP_NN_HALS(\n",
    "    **params_tca,\n",
    "    fixed_modes=modes_fixed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1f7bb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/roicat/lib/python3.11/site-packages/tensorly/backend/pytorch_backend.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error=0.3259412348270416\n",
      "iteration 1, reconstruction error: 0.3259415030479431, decrease = -2.682209014892578e-07\n",
      "iteration 2, reconstruction error: 0.3259415030479431, decrease = 0.0\n",
      "PARAFAC converged after 2 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Rank-12 Non-Negative CP decomposition."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tca.fit(s.to(DEVICE_tca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bae9a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_refit = model_tca.decomposition_\n",
    "cp_refit = tl.cp_tensor.CPTensor((cp_refit.weights.cpu(), [f.cpu() for f in cp_refit.factors]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f6ef42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_rec_refit = bnpm.similarity.cp_reconstruction_EV(\n",
    "    tensor_dense=s,\n",
    "    tensor_CP=cp_refit.factors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "302bb40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_rec_original = bnpm.similarity.cp_reconstruction_EV(\n",
    "    tensor_dense=s,\n",
    "    tensor_CP=cp_current.factors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7a2f855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7478)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EV_rec_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de86d222",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7047)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EV_rec_refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2da7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "tca_refit = {\n",
    "    'factors_refit': {key: val for key, val in zip(tca_template['factors_rearranged']['0'].keys(), cp_refit.factors)},\n",
    "    'modes_fixed': modes_fixed,\n",
    "    'EV_rec_original': EV_rec_original,\n",
    "    'EV_rec_refit': EV_rec_refit,\n",
    "    'directory_template': directory_FR_template,\n",
    "    'directory_current':directory_FR_current,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae9a2622",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnpm.h5_handling.simple_save(\n",
    "    dict_to_save=tca_refit,\n",
    "    path=str(Path(dir_save) / 'tca_refit.h5')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13a5986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb77ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c77ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c27405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc5ad3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60445666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c310af2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conda Environment: roicat\n",
      "device: 'cpu'\n",
      "device: 'cpu'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/roicat/lib/python3.11/site-packages/tensorly/backend/pytorch_backend.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error=0.3259409964084625\n",
      "iteration 1, reconstruction error: 0.3259415030479431, decrease = -5.066394805908203e-07\n",
      "iteration 2, reconstruction error: 0.3259415030479431, decrease = 0.0\n",
      "PARAFAC converged after 2 iterations\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] Unable to create file (unable to open file: name = '/home/rich/Desktop/tca_refit.h5', errno = 17, error message = 'File exists', flags = 15, o_flags = c2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 117\u001b[0m\n\u001b[1;32m    104\u001b[0m EV_rec_refit\n\u001b[1;32m    106\u001b[0m tca_refit \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactors_refit\u001b[39m\u001b[38;5;124m'\u001b[39m: {key: val\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tca_template[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactors_rearranged\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys(), cp_refit\u001b[38;5;241m.\u001b[39mfactors)},\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactors_original\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;28mstr\u001b[39m(ii): f\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m ii,f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cp_template\u001b[38;5;241m.\u001b[39mfactors)},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirectory_current\u001b[39m\u001b[38;5;124m'\u001b[39m:directory_FR_current,\n\u001b[1;32m    115\u001b[0m }\n\u001b[0;32m--> 117\u001b[0m \u001b[43mbnpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh5_handling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimple_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdict_to_save\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtca_refit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_save\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtca_refit.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/rich/Home_Linux_partition/github_repos/basic_neural_processing_modules/bnpm/h5_handling.py:262\u001b[0m, in \u001b[0;36msimple_save\u001b[0;34m(dict_to_save, path, use_compression, track_order, write_mode, verbose)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimple_save\u001b[39m(\n\u001b[1;32m    231\u001b[0m     dict_to_save, \n\u001b[1;32m    232\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    237\u001b[0m ):\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    Saves a python dict to an hdf file.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    Also allows for adding new data to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m            Whether or not to print out the h5 file hierarchy.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m     \u001b[43mwrite_dict_to_h5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdict_to_save\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_compression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_compression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrack_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrite_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_item_tree_pref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/rich/Home_Linux_partition/github_repos/basic_neural_processing_modules/bnpm/h5_handling.py:170\u001b[0m, in \u001b[0;36mwrite_dict_to_h5\u001b[0;34m(path_save, input_dict, use_compression, track_order, write_mode, show_item_tree_pref)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_dict_to_h5\u001b[39m(\n\u001b[1;32m    144\u001b[0m     path_save, \n\u001b[1;32m    145\u001b[0m     input_dict, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m     show_item_tree_pref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    150\u001b[0m ):\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    Writes an h5 file that matches the hierarchy and data within a python dict.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    This function calls the function 'make_h5_tree'\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m            Whether you'd like to print the item tree or not\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_save\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_mode\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m hf:\n\u001b[1;32m    171\u001b[0m         make_h5_tree(input_dict , hf , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, use_compression\u001b[38;5;241m=\u001b[39muse_compression, track_order\u001b[38;5;241m=\u001b[39mtrack_order)\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m show_item_tree_pref:\n",
      "File \u001b[0;32m/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/roicat/lib/python3.11/site-packages/h5py/_hl/files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    558\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    560\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    561\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    562\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    563\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    564\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    565\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    566\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 567\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/roicat/lib/python3.11/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw-\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mACC_EXCL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfcpl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mcreate(name, h5f\u001b[38;5;241m.\u001b[39mACC_TRUNC, fapl\u001b[38;5;241m=\u001b[39mfapl, fcpl\u001b[38;5;241m=\u001b[39mfcpl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:126\u001b[0m, in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] Unable to create file (unable to open file: name = '/home/rich/Desktop/tca_refit.h5', errno = 17, error message = 'File exists', flags = 15, o_flags = c2)"
     ]
    }
   ],
   "source": [
    "# widen jupyter notebook window\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important; }</style>\"))\n",
    "\n",
    "# check environment\n",
    "import os\n",
    "print(f'Conda Environment: ' + os.environ['CONDA_DEFAULT_ENV'])\n",
    "\n",
    "import copy\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorly as tl\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import bnpm\n",
    "\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "## Import face_rhythm TCA factors and spectrogram tensor\n",
    "\n",
    "dir_save = r'/home/rich/Desktop/'\n",
    "\n",
    "directory_FR_template = r'/media/rich/bigSSD/analysis_data/face_rhythm/mouse_0322N/20230430/run_from_o2'\n",
    "directory_FR_current = r'/media/rich/bigSSD/analysis_data/face_rhythm/mouse_0322N/20230502//jobNum_0'\n",
    "\n",
    "tca_template = bnpm.h5_handling.simple_load(str(Path(directory_FR_template) / 'analysis_files' / 'TCA.h5'))\n",
    "\n",
    "tca_current = bnpm.h5_handling.simple_load(str(Path(directory_FR_current) / 'analysis_files' / 'TCA.h5'))\n",
    "\n",
    "params_template = bnpm.file_helpers.json_load(str(Path(directory_FR_template) / 'params.json'))\n",
    "\n",
    "DEVICE_data = bnpm.torch_helpers.set_device(use_GPU=False)\n",
    "\n",
    "def cp_dict_to_cp_tensor(cp_dict, device='cpu'):\n",
    "    \"\"\"A function for converting a raw list of factor matrices into tensorly's CPTensor format\"\"\"\n",
    "    return tl.cp_tensor.CPTensor((None, [torch.as_tensor(v, dtype=torch.float32, device=device) for v in cp_dict.values()]))\n",
    "\n",
    "def make_cp_init(k_tensor, shape_dense_tensor, modes_fixed=[0,1,], device='cpu'):\n",
    "    \"\"\"Makes a CPTensor for initializing a TCA run. The k_tensor matrices will be used for each of the fixed modes and will be shuffle permuted for each of the non-fixed modes.\"\"\"\n",
    "    import copy\n",
    "    n_modes = len(k_tensor)\n",
    "    kt = [None]*n_modes\n",
    "    for i_mode in range(len(kt)):\n",
    "        if i_mode in modes_fixed:\n",
    "            kt[i_mode] = torch.as_tensor(k_tensor[i_mode], dtype=torch.float32, device=device)\n",
    "        else:\n",
    "            perm = torch.randperm(shape_dense_tensor[i_mode])\n",
    "            kt[i_mode] = torch.as_tensor(k_tensor[i_mode], dtype=torch.float32, device=device)[perm]\n",
    "        \n",
    "    return tl.cp_tensor.CPTensor((None, kt))\n",
    "\n",
    "spec_current = bnpm.h5_handling.simple_load(str(Path(directory_FR_current) / 'analysis_files' / 'VQT_Analyzer.h5'))\n",
    "\n",
    "## Prepare the current session spectrogram for refitting\n",
    "### flatten the (xy points) dimension\n",
    "s = spec_current['spectrograms']['0'].copy()\n",
    "s = s.transpose(2,3,0,1)\n",
    "s = s.reshape(s.shape[0], s.shape[1], -1)\n",
    "s = s.transpose(2,0,1)\n",
    "s = torch.as_tensor(s, dtype=torch.float32, device=DEVICE_data)\n",
    "\n",
    "## prepare tca factors into a tensorly CPTensor\n",
    "cp_template = cp_dict_to_cp_tensor(tca_template['factors_rearranged']['0'], device=DEVICE_data)\n",
    "cp_current = cp_dict_to_cp_tensor(tca_current['factors_rearranged']['0'], device=DEVICE_data)\n",
    "\n",
    "\n",
    "DEVICE_tca = bnpm.torch_helpers.set_device(use_GPU=False)\n",
    "\n",
    "modes_fixed = [0,1,]\n",
    "\n",
    "cp_init = make_cp_init(cp_template.factors, s.shape, modes_fixed=modes_fixed, device=DEVICE_tca)\n",
    "\n",
    "params_tca = copy.deepcopy(params_template['TCA']['fit']['params_method'])\n",
    "\n",
    "params_tca['n_iter_max'] = 100\n",
    "params_tca['init'] = cp_init\n",
    "\n",
    "model_tca = tl.decomposition.CP_NN_HALS(\n",
    "    **params_tca,\n",
    "    fixed_modes=modes_fixed,\n",
    ")\n",
    "\n",
    "model_tca.fit(s.to(DEVICE_tca))\n",
    "\n",
    "cp_refit = model_tca.decomposition_\n",
    "cp_refit = tl.cp_tensor.CPTensor((cp_refit.weights.cpu(), [f.cpu() for f in cp_refit.factors]))\n",
    "\n",
    "EV_rec_refit = bnpm.similarity.cp_reconstruction_EV(\n",
    "    tensor_dense=s,\n",
    "    tensor_CP=cp_refit.factors,\n",
    ")\n",
    "\n",
    "EV_rec_original = bnpm.similarity.cp_reconstruction_EV(\n",
    "    tensor_dense=s,\n",
    "    tensor_CP=cp_current.factors,\n",
    ")\n",
    "\n",
    "EV_rec_original\n",
    "\n",
    "EV_rec_refit\n",
    "\n",
    "tca_refit = {\n",
    "    'factors_refit': {key: val.cpu().numpy() for key, val in zip(tca_template['factors_rearranged']['0'].keys(), cp_refit.factors)},\n",
    "    'factors_original': {str(ii): f.cpu().numpy() for ii,f in enumerate(cp_template.factors)},\n",
    "    'cp_init': {str(ii): f.cpu().numpy() for ii,f in enumerate(cp_init.factors)},\n",
    "    'modes_fixed': modes_fixed,\n",
    "    'EV_rec_original': EV_rec_original,\n",
    "    'EV_rec_refit': EV_rec_refit,\n",
    "    'directory_template': directory_FR_template,\n",
    "    'directory_current':directory_FR_current,\n",
    "}\n",
    "\n",
    "bnpm.h5_handling.simple_save(\n",
    "    dict_to_save=tca_refit,\n",
    "    path=str(Path(dir_save) / 'tca_refit.h5'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc56ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd13de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d229cb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
